{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import pickle\n",
    "from numba import njit\n",
    "import librosa as lb\n",
    "import librosa.display\n",
    "from skimage.filters import threshold_li, threshold_niblack, threshold_triangle, threshold_isodata, threshold_mean\n",
    "from skimage.filters import threshold_otsu\n",
    "import time\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import os\n",
    "import multiprocessing\n",
    "from scipy.spatial.distance import cdist\n",
    "import pandas as pd\n",
    "from numba import prange, njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chroma(audio,sr=22050,H=1024,N=2048):\n",
    "    chroma = lb.feature.chroma_stft(y=audio, sr=sr, norm=2, hop_length=H, n_fft=N)\n",
    "    return chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cqt(audio, sr = 22050, hop_length = 1024, bins = 12):\n",
    "    return np.abs(lb.core.cqt(audio, n_bins = 8 * bins, bins_per_octave = bins, norm = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(path):\n",
    "    audio, sr = lb.core.load(path)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# piano_audio = get_audio(\"data/Audio/piano/piano1.m4a\")\n",
    "# violin_audio = get_audio('data/Audio/violin/violin1.mp3')\n",
    "# cello_audio = get_audio('data/Audio/cello/cello1.mp3')\n",
    "# fullmix_audio_1 = get_audio('data/Audio/fullmix/fullmix1.mp3')\n",
    "# fullmix_audio_2 = get_audio('data/Audio/fullmix/fullmix2.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "DTYPE_INT32 = np.int32\n",
    "ctypedef np.int32_t DTYPE_INT32_t\n",
    "\n",
    "DTYPE_FLOAT = np.float64\n",
    "ctypedef np.float64_t DTYPE_FLOAT_t\n",
    "\n",
    "cdef DTYPE_FLOAT_t MAX_FLOAT = float('inf')\n",
    "\n",
    "# careful, without bounds checking can mess up memory - also can't use negative indices I think (like x[-1])\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "def DTW_Cost_To_AccumCostAndSteps(Cin, parameter):\n",
    "    '''\n",
    "    Inputs\n",
    "        C: The cost Matrix\n",
    "    '''\n",
    "\n",
    "\n",
    "    '''\n",
    "    Section for checking and catching errors in the inputs\n",
    "    '''\n",
    "\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] C\n",
    "    try:\n",
    "        C = np.array(Cin, dtype=DTYPE_FLOAT)\n",
    "    except TypeError:\n",
    "        print(bcolors.FAIL + \"FAILURE: The type of the cost matrix is wrong - please pass in a 2-d numpy array\" + bcolors.ENDC)\n",
    "        return [-1, -1, -1]\n",
    "    except ValueError:\n",
    "        print(bcolors.FAIL + \"FAILURE: The type of the elements in the cost matrix is wrong - please have each element be a float (perhaps you passed in a matrix of ints?)\" + bcolors.ENDC)\n",
    "        return [-1, -1, -1]\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=1] dn\n",
    "    cdef np.ndarray[np.uint32_t, ndim=1] dm\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=1] dw\n",
    "    # make sure dn, dm, and dw are setup\n",
    "    # dn loading and exception handling\n",
    "    if ('dn'  in parameter.keys()):\n",
    "        try:\n",
    "\n",
    "            dn = np.array(parameter['dn'], dtype=np.uint32)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dn (row steps) is wrong - please pass in a 1-d numpy array that holds uint32s\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"The type of the elements in dn (row steps) is wrong - please have each element be a uint32 (perhaps you passed a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.uint32)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        dn = np.array([1, 1, 0], dtype=np.uint32)\n",
    "    # dm loading and exception handling\n",
    "    if 'dm'  in parameter.keys():\n",
    "        try:\n",
    "            dm = np.array(parameter['dm'], dtype=np.uint32)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dm (col steps) is wrong - please pass in a 1-d numpy array that holds uint32s\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of the elements in dm (col steps) is wrong - please have each element be a uint32 (perhaps you passed a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.uint32)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        print(bcolors.FAIL + \"dm (col steps) was not passed in (gave default value [1,0,1]) \" + bcolors.ENDC)\n",
    "        dm = np.array([1, 0, 1], dtype=np.uint32)\n",
    "    # dw loading and exception handling\n",
    "    if 'dw'  in parameter.keys():\n",
    "        try:\n",
    "            dw = np.array(parameter['dw'], dtype=DTYPE_FLOAT)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dw (step weights) is wrong - please pass in a 1-d numpy array that holds floats\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"FAILURE:The type of the elements in dw (step weights) is wrong - please have each element be a float (perhaps you passed ints or a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.float64)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        dw = np.array([1, 1, 1], dtype=DTYPE_FLOAT)\n",
    "        print(bcolors.FAIL + \"dw (step weights) was not passed in (gave default value [1,1,1]) \" + bcolors.ENDC)\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Section where types are given to the variables we're going to use \n",
    "    '''\n",
    "    # create matrices to store our results (D and E)\n",
    "    cdef DTYPE_INT32_t numRows = C.shape[0] # only works with np arrays, use np.shape(x) will work on lists? want to force to use np though?\n",
    "    cdef DTYPE_INT32_t numCols = C.shape[1]\n",
    "    cdef DTYPE_INT32_t numDifSteps = np.size(dw)\n",
    "\n",
    "    cdef unsigned int maxRowStep = max(dn)\n",
    "    cdef unsigned int maxColStep = max(dm)\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=2] steps = np.zeros((numRows,numCols), dtype=np.uint32)\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost = np.ones((maxRowStep + numRows, maxColStep + numCols), dtype=DTYPE_FLOAT) * MAX_FLOAT\n",
    "\n",
    "    cdef DTYPE_FLOAT_t bestCost\n",
    "    cdef DTYPE_INT32_t bestCostIndex\n",
    "    cdef DTYPE_FLOAT_t costForStep\n",
    "    cdef unsigned int row, col\n",
    "    cdef unsigned int stepIndex\n",
    "\n",
    "    '''\n",
    "    The start of the actual algorithm, now that all our variables are set up\n",
    "    '''\n",
    "    # initializing the cost matrix - depends on whether its subsequence DTW\n",
    "    # essentially allow us to hop on the bottom anywhere (so could start partway through one of the signals)\n",
    "    if parameter['SubSequence']:\n",
    "        for col in range(numCols):\n",
    "            accumCost[maxRowStep, col + maxColStep] = C[0, col]\n",
    "    else:\n",
    "        accumCost[maxRowStep, maxColStep] = C[0,0]\n",
    "\n",
    "    # filling the accumulated cost matrix\n",
    "    for row in range(maxRowStep, numRows + maxRowStep, 1):\n",
    "        for col in range(maxColStep, numCols + maxColStep, 1):\n",
    "            bestCost = accumCost[<unsigned int>row, <unsigned int>col] # initialize with what's there - so if is an entry point, then can start low\n",
    "            bestCostIndex = 0\n",
    "            # go through each step, find the best one\n",
    "            for stepIndex in range(numDifSteps):\n",
    "                #costForStep = accumCost[<unsigned int>(row - dn[<unsigned int>(stepIndex)]), <unsigned int>(col - dm[<unsigned int>(stepIndex)])] + dw[<unsigned int>(stepIndex)] * C[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)]\n",
    "                costForStep = accumCost[<unsigned int>((row - dn[(stepIndex)])), <unsigned int>((col - dm[(stepIndex)]))] + dw[stepIndex] * C[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)]\n",
    "                if costForStep < bestCost:\n",
    "                    bestCost = costForStep\n",
    "                    bestCostIndex = stepIndex\n",
    "            # save the best cost and best cost index\n",
    "            accumCost[row, col] = bestCost\n",
    "            steps[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)] = bestCostIndex\n",
    "\n",
    "    # return the accumulated cost along with the matrix of steps taken to achieve that cost\n",
    "    return [accumCost[maxRowStep:, maxColStep:], steps]\n",
    "\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "def DTW_GetPath(np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost, np.ndarray[np.uint32_t, ndim=2] stepsForCost, parameter):\n",
    "    '''\n",
    "\n",
    "    Parameter should have: 'dn', 'dm', 'dw', 'SubSequence'\n",
    "    '''\n",
    "\n",
    "    cdef np.ndarray[unsigned int, ndim=1] dn\n",
    "    cdef np.ndarray[unsigned int, ndim=1] dm\n",
    "    cdef np.uint8_t subseq\n",
    "    # make sure dn, dm, and dw are setup\n",
    "    if ('dn'  in parameter.keys()):\n",
    "        dn = parameter['dn']\n",
    "    else:\n",
    "        dn = np.array([1, 1, 0], dtype=DTYPE_INT32)\n",
    "    if 'dm'  in parameter.keys():\n",
    "        dm = parameter['dm']\n",
    "    else:\n",
    "        dm = np.array([1, 0, 1], dtype=DTYPE_INT32)\n",
    "    if 'SubSequence' in parameter.keys():\n",
    "        subseq = parameter['SubSequence']\n",
    "    else:\n",
    "        subseq = 0\n",
    "\n",
    "    cdef np.uint32_t numRows\n",
    "    cdef np.uint32_t numCols\n",
    "    cdef np.uint32_t curRow\n",
    "    cdef np.uint32_t curCol\n",
    "    cdef np.uint32_t endCol\n",
    "    cdef DTYPE_FLOAT_t endCost\n",
    "\n",
    "    numRows = accumCost.shape[0]\n",
    "    numCols = accumCost.shape[1]\n",
    "\n",
    "    # either start at the far corner (non sub-sequence)\n",
    "    # or start at the lowest cost entry in the last row (sub-sequence)\n",
    "    # where all of the signal along the row has been used, but only a \n",
    "    # sub-sequence of the signal along the columns has to be used\n",
    "    curRow = numRows - 1\n",
    "    if subseq:\n",
    "        curCol = np.argmin(accumCost[numRows - 1, :])\n",
    "    else:\n",
    "        curCol = numCols - 1\n",
    "\n",
    "    endCol = curCol\n",
    "    endCost = accumCost[curRow, curCol]\n",
    "\n",
    "    cdef np.uint32_t curRowStep\n",
    "    cdef np.uint32_t curColStep\n",
    "    cdef np.uint32_t curStepIndex\n",
    "\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=2] path = np.zeros((2, numRows + numCols), dtype=np.uint32) # make as large as could need, then chop at the end\n",
    "    path[0, 0] = curRow\n",
    "    path[1, 0] = curCol\n",
    "\n",
    "    cdef np.uint32_t stepsInPath = 1 # starts at one, we add in one before looping\n",
    "    cdef np.uint32_t stepIndex = 0\n",
    "    cdef np.int8_t done = (subseq and curRow == 0) or (curRow == 0 and curCol == 0)\n",
    "    while not done:\n",
    "        if accumCost[curRow, curCol] == MAX_FLOAT:\n",
    "            print('A path is not possible')\n",
    "            break\n",
    "\n",
    "        # you're done if you've made it to the bottom left (non sub-sequence)\n",
    "        # or just the bottom (sub-sequence)\n",
    "        # find the step size\n",
    "        curStepIndex = stepsForCost[curRow, curCol]\n",
    "        curRowStep = dn[curStepIndex]\n",
    "        curColStep = dm[curStepIndex]\n",
    "        # backtrack by 1 step\n",
    "        curRow = curRow - curRowStep\n",
    "        curCol = curCol - curColStep\n",
    "        # add your new location onto the path\n",
    "        path[0, stepsInPath] = curRow\n",
    "        path[1, stepsInPath] = curCol\n",
    "        stepsInPath = stepsInPath + 1\n",
    "        # check to see if you're done\n",
    "        done = (subseq and curRow == 0) or (curRow == 0 and curCol == 0)\n",
    "\n",
    "    # reverse the path (a matrix with two rows) and return it\n",
    "    return [np.fliplr(path[:, 0:stepsInPath]), endCol, endCost]\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(X,Y):\n",
    "    cost = cdist(X,Y,'cosine')\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_part_to_fullmix(query, ref, steps = [1, 1, 1, 2, 2, 1], weights = [1, 1, 2]):\n",
    "    assert len(steps) % 2 == 0, \"The length of steps must be even.\"\n",
    "    dn = np.array(steps[::2], dtype=np.uint32)\n",
    "    dm = np.array(steps[1::2], dtype=np.uint32)\n",
    "    dw = weights\n",
    "    subsequence = True\n",
    "    parameter = {'dn': dn, 'dm': dm, 'dw': dw, 'SubSequence': subsequence}\n",
    "\n",
    "    # Compute cost matrix\n",
    "    cost = calculate_cost_fast(query, ref)\n",
    "    \n",
    "    # DTW\n",
    "    [D, s] = DTW_Cost_To_AccumCostAndSteps(cost, parameter)\n",
    "    [wp, endCol, endCost] = DTW_GetPath(D, s, parameter)\n",
    "\n",
    "    # Reformat the output\n",
    "    wp = wp.T[::-1]\n",
    "    return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_audio(query, ref, steps = [1,1,1,2,2,1], weights = [2, 3, 3]):\n",
    "    # set params\n",
    "    assert len(steps) % 2 == 0, \"The length of steps must be even.\"\n",
    "    dn = np.array(steps[::2], dtype=np.uint32)\n",
    "    dm = np.array(steps[1::2], dtype=np.uint32)\n",
    "    dw = weights\n",
    "    subsequence = True\n",
    "    parameter = {'dn': dn, 'dm': dm, 'dw': dw, 'SubSequence': subsequence}\n",
    "\n",
    "    # Compute cost matrix\n",
    "    cost = cosine_distance(query.T, ref.T)\n",
    "\n",
    "    # DTW\n",
    "    [D, s] = DTW_Cost_To_AccumCostAndSteps(cost, parameter)\n",
    "    [wp, endCol, endCost] = DTW_GetPath(D, s, parameter)\n",
    "\n",
    "    # Reformat the output\n",
    "    wp = wp.T[::-1]\n",
    "    return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_time(frame, hop_length = 1024, sr = 22050):\n",
    "    return frame * hop_length / sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_frame(time, hop_length = 1024, sr = 22050):\n",
    "    return time * sr / hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateErrors(data, annotfile, gtfile, hop_length = 1024, sr = 22050, debug = False):\n",
    "    if not os.path.exists(annotfile):\n",
    "        return []\n",
    "    wp = np.array(sorted(data, key = lambda x: x[0]))\n",
    "    query_preds = wp[:, 0]\n",
    "    ref_preds = wp[:, 1]\n",
    "    query_to_ref = np.interp(list(range(max(query_preds[-1], ref_preds[-1]) + 1)), query_preds, ref_preds)\n",
    "\n",
    "    data_gt = np.genfromtxt(gtfile, delimiter=',')\n",
    "    gt_mapping = {}\n",
    "    with open(gtfile,'r') as data_gt:\n",
    "        for line in data_gt:\n",
    "            time = float(line.strip().split()[0])\n",
    "            idx = int(line.strip().split()[1])\n",
    "            gt_mapping[idx] = time\n",
    "        \n",
    "    data_annot = np.genfromtxt(annotfile, delimiter=',')\n",
    "    errors = []\n",
    "    clicks = []\n",
    "    idxs = []\n",
    "    with open(annotfile,'r') as data_annot:\n",
    "        for line in data_annot:\n",
    "            time = float(line.strip().split()[0])\n",
    "            idx = int(line.strip().split()[1])\n",
    "            \n",
    "            frame = int(np.round(time_to_frame(time)))\n",
    "            ref_frame = query_to_ref[frame]\n",
    "            pred_ref_time = frame_to_time(ref_frame)\n",
    "            if debug:\n",
    "                clicks.append(pred_ref_time)\n",
    "            if idx in gt_mapping:\n",
    "                error = np.abs(pred_ref_time - gt_mapping[idx])\n",
    "                idxs.append(idx)\n",
    "                errors.append(error)\n",
    "    if debug:\n",
    "        return errors, clicks\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tolerances(errors, tols = np.arange(0,1,1/1000)):\n",
    "    errors = np.array(errors)\n",
    "    errorRates = []\n",
    "    for tol in tols:\n",
    "        toAdd = np.sum(errors > tol) * 1.0 / len(errors)\n",
    "        errorRates.append(toAdd)\n",
    "    return errorRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel = True)\n",
    "def calculate_cost_fast(query, ref):\n",
    "    m, n1 = query.shape\n",
    "    m, n2 = ref.shape\n",
    "    result = np.zeros((n1, n2))\n",
    "    for j1 in prange(n1):\n",
    "        for j2 in prange(n2):\n",
    "            for i in prange(m):\n",
    "                result[j1, j2] += query[i, j1] * ref[i, j2]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(query, ref):\n",
    "    cost = calculate_cost_fast(query, ref)\n",
    "    row_sums = query.sum(axis = 0) * -1\n",
    "    result = cost / row_sums[:, None]\n",
    "    result[result == np.inf] = 0\n",
    "    result = np.nan_to_num(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_binarized_cqts(query, ref, steps = [1,1,1,2,2,1], weights = [1,1,2]):\n",
    "    # set params\n",
    "    assert len(steps) % 2 == 0, \"The length of steps must be even.\"\n",
    "    dn = np.array(steps[::2], dtype=np.uint32)\n",
    "    dm = np.array(steps[1::2], dtype=np.uint32)\n",
    "    dw = weights\n",
    "    subsequence = True\n",
    "    parameter = {'dn': dn, 'dm': dm, 'dw': dw, 'SubSequence': subsequence}\n",
    "\n",
    "    # Compute cost matrix\n",
    "    cost = calculate_cost(query, ref)\n",
    "\n",
    "    # DTW\n",
    "    [D, s] = DTW_Cost_To_AccumCostAndSteps(cost, parameter)\n",
    "    [wp, endCol, endCost] = DTW_GetPath(D, s, parameter)\n",
    "\n",
    "    # Reformat the output\n",
    "    wp = wp.T[::-1]\n",
    "    return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch_part(query, ref, alignment):\n",
    "    m, n = ref.shape\n",
    "    feature_stretch = np.zeros((m, n))\n",
    "    used = set(alignment[:, 1])\n",
    "    for query_idx, ref_idx in alignment:\n",
    "        feature_stretch[:, ref_idx] = query[:, query_idx]\n",
    "    for j in range(n):\n",
    "        if j not in used:\n",
    "            feature_stretch[:, j] = feature_stretch[:, j-1]\n",
    "    return feature_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel = True)\n",
    "def subtract_part_helper(stretched_cqt, fullmix_cqt):\n",
    "    m, n = stretched_cqt.shape\n",
    "    assert stretched_cqt.shape == fullmix_cqt.shape\n",
    "    \n",
    "    for i in prange(m):\n",
    "        for j in prange(n):\n",
    "            fullmix_cqt[i, j] -= stretched_cqt[i, j]\n",
    "            fullmix_cqt[i, j] = max(fullmix_cqt[i, j], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_part(stretched_part, ref):\n",
    "    subtract_part_helper(stretched_part, ref)\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_cqt(cqt):\n",
    "    rows = cqt.shape[0]\n",
    "    bin_size = 12\n",
    "    context = 6\n",
    "    binarized = []\n",
    "    for i in range(0, rows, bin_size):\n",
    "        if i - context < 0:\n",
    "            data = cqt[:i + context]\n",
    "        elif i + context >= rows:\n",
    "            data = cqt[i - context:]\n",
    "        else:\n",
    "            data = cqt[i-context: i+context+bin_size]\n",
    "        thresh = threshold_triangle(data)\n",
    "        frequency_bin = cqt[i: i+bin_size]\n",
    "        x1 = frequency_bin > thresh\n",
    "        binarized.extend(x1)\n",
    "    return np.array(binarized).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch_segments(segments, wp):\n",
    "    wp = np.array(sorted(wp, key = lambda x: x[0]))\n",
    "    query_preds = wp[:, 0]\n",
    "    ref_preds = wp[:, 1]\n",
    "    query_to_ref = np.interp(list(range(max(query_preds[-1], ref_preds[-1]) + 1)), query_preds, ref_preds)\n",
    "    n = len(query_to_ref) - 1\n",
    "    segments[-1][1] = min(segments[-1][1], n)\n",
    "    return [[int(query_to_ref[a]), int(query_to_ref[b])] for (a, b) in segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_segments(segments, part_cqt, fullmix_cqt):\n",
    "    alphas = np.concatenate([np.linspace(0.1, 1.0, num = 20), np.arange(1, 11, 0.3), np.arange(10, 510, 10)])\n",
    "    for segment in segments:\n",
    "        part_segment = part_cqt[:, segment[0]: segment[1] + 1]\n",
    "        fullmix_segment = fullmix_cqt[:, segment[0]: segment[1] + 1]\n",
    "        assert part_segment.shape == fullmix_segment.shape\n",
    "        best = float('-inf')\n",
    "        result = 0\n",
    "        for alpha in alphas:\n",
    "            val = np.sum(np.minimum(part_segment*alpha, fullmix_segment) - np.maximum(part_segment*alpha - fullmix_segment, 0))\n",
    "            if val > best:\n",
    "                best = val\n",
    "                result = alpha\n",
    "        part_cqt[:, segment[0]: segment[1] + 1] *= result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssa(part_cqt, fullmix_cqt, segments = []):\n",
    "    part_binarized, fullmix_binarized = binarize_cqt(part_cqt), binarize_cqt(fullmix_cqt)\n",
    "    print(part_binarized.shape)\n",
    "    wp = align_binarized_cqts(part_binarized, fullmix_binarized)\n",
    "    stretched_part = time_stretch_part(part_cqt, fullmix_cqt, wp)\n",
    "    if segments:\n",
    "        stretched_segments = stretch_segments(segments, wp)\n",
    "        weight_segments(stretched_segments, stretched_part, fullmix_cqt)\n",
    "    subtract_part(stretched_part, fullmix_cqt)\n",
    "    return fullmix_cqt, wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silence_intervals(silence_indices):\n",
    "    cur_interval = []\n",
    "    start = silence_indices[0]\n",
    "    for i in range(len(silence_indices) - 1):\n",
    "        if silence_indices[i] + 1 != silence_indices[i+1]:\n",
    "            cur_interval.append((start, silence_indices[i]))\n",
    "            start = silence_indices[i+1]\n",
    "    cur_interval.append((start, silence_indices[-1]))\n",
    "    silence_intervals = []\n",
    "    for start, end in cur_interval:\n",
    "        start_time = frame_to_time(start)\n",
    "        end_time = frame_to_time(end)\n",
    "        if end_time - start_time < 2:\n",
    "            continue\n",
    "        silence_intervals.append([start, end])\n",
    "    return silence_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(total_energies):\n",
    "    model = mixture.GaussianMixture(n_components=3, covariance_type=\"full\")\n",
    "    model.fit(total_energies)\n",
    "    pi, mu, sigma = model.weights_.flatten(), model.means_.flatten(), np.sqrt(model.covariances_.flatten())\n",
    "    max_idx = np.argmax(mu)\n",
    "    threshold = mu[max_idx] - 4 * sigma[max_idx]\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssa_a(part_cqt, fullmix_cqt, segments = []):\n",
    "    wp = align_part_to_fullmix(part_cqt, fullmix_cqt)\n",
    "    stretched_part = time_stretch_part(part_cqt, fullmix_cqt, wp)\n",
    "    if segments:\n",
    "        stretched_segments = stretch_segments(segments, wp)\n",
    "        weight_segments(stretched_segments, stretched_part, fullmix_cqt)\n",
    "    subtract_part(stretched_part, fullmix_cqt)\n",
    "    return fullmix_cqt, wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(audio, H=1024, N=2048):\n",
    "    stft = librosa.stft(audio, n_fft=N, hop_length=H)\n",
    "    energies = np.sum(np.square(abs(stft)), axis=0)\n",
    "    L = 32\n",
    "    total_energies = []\n",
    "    for i in range(len(energies)-L):\n",
    "        total_energies.append(sum(energies[i:i+L]))\n",
    "        \n",
    "    total_energies = np.log(total_energies).reshape(-1, 1)\n",
    "    threshold = get_threshold(total_energies)\n",
    "    \n",
    "    is_silence = [False] * (L//2 - 1)\n",
    "    for energy in total_energies:\n",
    "        if energy <= threshold:\n",
    "            is_silence.append(True)\n",
    "        else:\n",
    "            is_silence.append(False)\n",
    "    is_silence.extend([False] * (L//2))\n",
    "    silence_indices = np.where(np.array(is_silence) == True)[0]\n",
    "    silence_intervals = get_silence_intervals(silence_indices)\n",
    "    nonsilence_segments = []\n",
    "    cur = 0\n",
    "    for start, end in silence_intervals:\n",
    "        nonsilence_segments.append([cur, start])\n",
    "        cur = end + 1\n",
    "    nonsilence_segments.append([cur, len(is_silence)])\n",
    "    return nonsilence_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "basepath = '/home/dyang/URMP-clean/data/train'\n",
    "pieces = os.listdir(basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01_Jupiter_vn_vc',\n",
       " '02_Sonata_vn_vn',\n",
       " '03_Dance_fl_cl',\n",
       " '04_Allegro_fl_fl',\n",
       " '07_GString_tpt_tbn',\n",
       " '11_Maria_ob_vc',\n",
       " '12_Spring_vn_vn_vc',\n",
       " '15_Surprise_tpt_tpt_tbn',\n",
       " '16_Surprise_tpt_tpt_sax',\n",
       " '18_Nocturne_vn_fl_tpt',\n",
       " '21_Rejouissance_cl_tbn_tba',\n",
       " '22_Rejouissance_sax_tbn_tba',\n",
       " '27_King_vn_vn_va_sax',\n",
       " '28_Fugue_fl_ob_cl_bn',\n",
       " '29_Fugue_fl_fl_ob_cl',\n",
       " '33_Elise_tpt_tpt_hn_tbn',\n",
       " '35_Rondeau_vn_vn_va_db',\n",
       " '36_Rondeau_vn_vn_va_vc',\n",
       " '38_Jerusalem_vn_vn_va_vc_db',\n",
       " '39_Jerusalem_vn_vn_va_sax_db']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dyang/URMP-clean/data/train/02_Sonata_vn_vn/I0.wav\n",
      "8.918239277290963\n",
      "/home/dyang/URMP-clean/data/train/02_Sonata_vn_vn/I1.wav\n",
      "11.572009753766972\n",
      "/home/dyang/URMP-clean/data/train/02_Sonata_vn_vn/I0.wav\n",
      "8.881432357232478\n",
      "/home/dyang/URMP-clean/data/train/02_Sonata_vn_vn/I1.wav\n",
      "11.194332148379736\n",
      "/home/dyang/URMP-clean/data/train/02_Sonata_vn_vn/I0.wav\n",
      "8.050619289380737\n",
      "/home/dyang/URMP-clean/data/train/02_Sonata_vn_vn/I1.wav\n",
      "9.94669568343538\n"
     ]
    }
   ],
   "source": [
    "piece = pieces[1]\n",
    "for num in range(3):\n",
    "    piece_path = os.path.join(basepath, piece)\n",
    "    fullmix_path = os.path.join(piece_path, f'Vocoder{num}.wav')\n",
    "    fullmix_audio = get_audio(fullmix_path)\n",
    "    fullmix_cqt = calculate_cqt(fullmix_audio)\n",
    "    fullmix_annot = os.path.join(piece_path,f'Vocoder{num}.txt')\n",
    "    instrument_paths = sorted(glob.glob(os.path.join(piece_path,'I*.wav')))\n",
    "    cqts = []\n",
    "    all_errs = []\n",
    "    segments = []\n",
    "    clicks = []\n",
    "    for idx, instrument_path in enumerate(instrument_paths):\n",
    "        print(instrument_path)\n",
    "        audio = get_audio(instrument_path)\n",
    "        cqt = calculate_cqt(audio)\n",
    "        segments = get_segments(audio)\n",
    "        cqts.append(cqt)\n",
    "        fullmix_cqt, align = ssa_a(cqt, fullmix_cqt)\n",
    "        annot = os.path.join(piece_path,os.path.basename(instrument_path).replace('wav','txt'))\n",
    "        errors, click = calculateErrors(align, annot, fullmix_annot, debug = True)\n",
    "        print(np.average(errors))\n",
    "        all_errs.extend(errors)\n",
    "        clicks.extend(click)\n",
    "#     with open(f'tols_test/baseline1/{piece}{num}.pkl','wb') as f:\n",
    "#         pickle.dump(all_errs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
