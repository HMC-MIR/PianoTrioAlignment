{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtractive alignment + CQT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the alignment between the CQT representations of the part and the full mix recordings to perform the subtractive alignment algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import pickle\n",
    "from numba import njit, prange\n",
    "import librosa as lb\n",
    "import librosa.display\n",
    "from skimage.filters import threshold_triangle\n",
    "import time\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import os\n",
    "import multiprocessing\n",
    "from scipy.spatial.distance import cdist\n",
    "import pandas as pd\n",
    "from sklearn import mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cqt(audio, sr = 22050, hop_length = 512, bins = 12):\n",
    "    return np.abs(lb.core.cqt(audio, n_bins = 8 * bins, bins_per_octave = bins, norm = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(path):\n",
    "    audio, sr = lb.core.load(path)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in all the audio recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kji/.local/lib/python3.6/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/kji/.local/lib/python3.6/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/kji/.local/lib/python3.6/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/kji/.local/lib/python3.6/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/kji/.local/lib/python3.6/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    }
   ],
   "source": [
    "piano1_audio = get_audio(\"data/Audio/piano/piano3.m4a\")\n",
    "violin1_audio = get_audio('data/Audio/violin/violin3.mp3')\n",
    "cello1_audio = get_audio('data/Audio/cello/cello3.mp3')\n",
    "# piano2_audio = get_audio(\"data/Audio/piano/piano4.m4a\")\n",
    "# violin2_audio = get_audio('data/Audio/violin/violin4.mp3')\n",
    "# cello2_audio = get_audio('data/Audio/cello/cello4.mp3')\n",
    "fullmix_audio_1 = get_audio('data/Audio/fullmix/fullmix3.mp3')\n",
    "fullmix_audio_2 = get_audio('data/Audio/fullmix/fullmix4.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsequence DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "DTYPE_INT32 = np.int32\n",
    "ctypedef np.int32_t DTYPE_INT32_t\n",
    "\n",
    "DTYPE_FLOAT = np.float64\n",
    "ctypedef np.float64_t DTYPE_FLOAT_t\n",
    "\n",
    "cdef DTYPE_FLOAT_t MAX_FLOAT = float('inf')\n",
    "\n",
    "# careful, without bounds checking can mess up memory - also can't use negative indices I think (like x[-1])\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "def DTW_Cost_To_AccumCostAndSteps(Cin, parameter):\n",
    "    '''\n",
    "    Inputs\n",
    "        C: The cost Matrix\n",
    "    '''\n",
    "\n",
    "\n",
    "    '''\n",
    "    Section for checking and catching errors in the inputs\n",
    "    '''\n",
    "\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] C\n",
    "    try:\n",
    "        C = np.array(Cin, dtype=DTYPE_FLOAT)\n",
    "    except TypeError:\n",
    "        print(bcolors.FAIL + \"FAILURE: The type of the cost matrix is wrong - please pass in a 2-d numpy array\" + bcolors.ENDC)\n",
    "        return [-1, -1, -1]\n",
    "    except ValueError:\n",
    "        print(bcolors.FAIL + \"FAILURE: The type of the elements in the cost matrix is wrong - please have each element be a float (perhaps you passed in a matrix of ints?)\" + bcolors.ENDC)\n",
    "        return [-1, -1, -1]\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=1] dn\n",
    "    cdef np.ndarray[np.uint32_t, ndim=1] dm\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=1] dw\n",
    "    # make sure dn, dm, and dw are setup\n",
    "    # dn loading and exception handling\n",
    "    if ('dn'  in parameter.keys()):\n",
    "        try:\n",
    "\n",
    "            dn = np.array(parameter['dn'], dtype=np.uint32)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dn (row steps) is wrong - please pass in a 1-d numpy array that holds uint32s\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"The type of the elements in dn (row steps) is wrong - please have each element be a uint32 (perhaps you passed a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.uint32)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        dn = np.array([1, 1, 0], dtype=np.uint32)\n",
    "    # dm loading and exception handling\n",
    "    if 'dm'  in parameter.keys():\n",
    "        try:\n",
    "            dm = np.array(parameter['dm'], dtype=np.uint32)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dm (col steps) is wrong - please pass in a 1-d numpy array that holds uint32s\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of the elements in dm (col steps) is wrong - please have each element be a uint32 (perhaps you passed a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.uint32)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        print(bcolors.FAIL + \"dm (col steps) was not passed in (gave default value [1,0,1]) \" + bcolors.ENDC)\n",
    "        dm = np.array([1, 0, 1], dtype=np.uint32)\n",
    "    # dw loading and exception handling\n",
    "    if 'dw'  in parameter.keys():\n",
    "        try:\n",
    "            dw = np.array(parameter['dw'], dtype=DTYPE_FLOAT)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dw (step weights) is wrong - please pass in a 1-d numpy array that holds floats\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"FAILURE:The type of the elements in dw (step weights) is wrong - please have each element be a float (perhaps you passed ints or a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.float64)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        dw = np.array([1, 1, 1], dtype=DTYPE_FLOAT)\n",
    "        print(bcolors.FAIL + \"dw (step weights) was not passed in (gave default value [1,1,1]) \" + bcolors.ENDC)\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Section where types are given to the variables we're going to use \n",
    "    '''\n",
    "    # create matrices to store our results (D and E)\n",
    "    cdef DTYPE_INT32_t numRows = C.shape[0] # only works with np arrays, use np.shape(x) will work on lists? want to force to use np though?\n",
    "    cdef DTYPE_INT32_t numCols = C.shape[1]\n",
    "    cdef DTYPE_INT32_t numDifSteps = np.size(dw)\n",
    "\n",
    "    cdef unsigned int maxRowStep = max(dn)\n",
    "    cdef unsigned int maxColStep = max(dm)\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=2] steps = np.zeros((numRows,numCols), dtype=np.uint32)\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost = np.ones((maxRowStep + numRows, maxColStep + numCols), dtype=DTYPE_FLOAT) * MAX_FLOAT\n",
    "\n",
    "    cdef DTYPE_FLOAT_t bestCost\n",
    "    cdef DTYPE_INT32_t bestCostIndex\n",
    "    cdef DTYPE_FLOAT_t costForStep\n",
    "    cdef unsigned int row, col\n",
    "    cdef unsigned int stepIndex\n",
    "\n",
    "    '''\n",
    "    The start of the actual algorithm, now that all our variables are set up\n",
    "    '''\n",
    "    # initializing the cost matrix - depends on whether its subsequence DTW\n",
    "    # essentially allow us to hop on the bottom anywhere (so could start partway through one of the signals)\n",
    "    if parameter['SubSequence']:\n",
    "        for col in range(numCols):\n",
    "            accumCost[maxRowStep, col + maxColStep] = C[0, col]\n",
    "    else:\n",
    "        accumCost[maxRowStep, maxColStep] = C[0,0]\n",
    "\n",
    "    # filling the accumulated cost matrix\n",
    "    for row in range(maxRowStep, numRows + maxRowStep, 1):\n",
    "        for col in range(maxColStep, numCols + maxColStep, 1):\n",
    "            bestCost = accumCost[<unsigned int>row, <unsigned int>col] # initialize with what's there - so if is an entry point, then can start low\n",
    "            bestCostIndex = 0\n",
    "            # go through each step, find the best one\n",
    "            for stepIndex in range(numDifSteps):\n",
    "                #costForStep = accumCost[<unsigned int>(row - dn[<unsigned int>(stepIndex)]), <unsigned int>(col - dm[<unsigned int>(stepIndex)])] + dw[<unsigned int>(stepIndex)] * C[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)]\n",
    "                costForStep = accumCost[<unsigned int>((row - dn[(stepIndex)])), <unsigned int>((col - dm[(stepIndex)]))] + dw[stepIndex] * C[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)]\n",
    "                if costForStep < bestCost:\n",
    "                    bestCost = costForStep\n",
    "                    bestCostIndex = stepIndex\n",
    "            # save the best cost and best cost index\n",
    "            accumCost[row, col] = bestCost\n",
    "            steps[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)] = bestCostIndex\n",
    "\n",
    "    # return the accumulated cost along with the matrix of steps taken to achieve that cost\n",
    "    return [accumCost[maxRowStep:, maxColStep:], steps]\n",
    "\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "def DTW_GetPath(np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost, np.ndarray[np.uint32_t, ndim=2] stepsForCost, parameter):\n",
    "    '''\n",
    "\n",
    "    Parameter should have: 'dn', 'dm', 'dw', 'SubSequence'\n",
    "    '''\n",
    "\n",
    "    cdef np.ndarray[unsigned int, ndim=1] dn\n",
    "    cdef np.ndarray[unsigned int, ndim=1] dm\n",
    "    cdef np.uint8_t subseq\n",
    "    # make sure dn, dm, and dw are setup\n",
    "    if ('dn'  in parameter.keys()):\n",
    "        dn = parameter['dn']\n",
    "    else:\n",
    "        dn = np.array([1, 1, 0], dtype=DTYPE_INT32)\n",
    "    if 'dm'  in parameter.keys():\n",
    "        dm = parameter['dm']\n",
    "    else:\n",
    "        dm = np.array([1, 0, 1], dtype=DTYPE_INT32)\n",
    "    if 'SubSequence' in parameter.keys():\n",
    "        subseq = parameter['SubSequence']\n",
    "    else:\n",
    "        subseq = 0\n",
    "\n",
    "    cdef np.uint32_t numRows\n",
    "    cdef np.uint32_t numCols\n",
    "    cdef np.uint32_t curRow\n",
    "    cdef np.uint32_t curCol\n",
    "    cdef np.uint32_t endCol\n",
    "    cdef DTYPE_FLOAT_t endCost\n",
    "\n",
    "    numRows = accumCost.shape[0]\n",
    "    numCols = accumCost.shape[1]\n",
    "\n",
    "    # either start at the far corner (non sub-sequence)\n",
    "    # or start at the lowest cost entry in the last row (sub-sequence)\n",
    "    # where all of the signal along the row has been used, but only a \n",
    "    # sub-sequence of the signal along the columns has to be used\n",
    "    curRow = numRows - 1\n",
    "    if subseq:\n",
    "        curCol = np.argmin(accumCost[numRows - 1, :])\n",
    "    else:\n",
    "        curCol = numCols - 1\n",
    "\n",
    "    endCol = curCol\n",
    "    endCost = accumCost[curRow, curCol]\n",
    "\n",
    "    cdef np.uint32_t curRowStep\n",
    "    cdef np.uint32_t curColStep\n",
    "    cdef np.uint32_t curStepIndex\n",
    "\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=2] path = np.zeros((2, numRows + numCols), dtype=np.uint32) # make as large as could need, then chop at the end\n",
    "    path[0, 0] = curRow\n",
    "    path[1, 0] = curCol\n",
    "\n",
    "    cdef np.uint32_t stepsInPath = 1 # starts at one, we add in one before looping\n",
    "    cdef np.uint32_t stepIndex = 0\n",
    "    cdef np.int8_t done = (subseq and curRow == 0) or (curRow == 0 and curCol == 0)\n",
    "    while not done:\n",
    "        if accumCost[curRow, curCol] == MAX_FLOAT:\n",
    "            print('A path is not possible')\n",
    "            break\n",
    "\n",
    "        # you're done if you've made it to the bottom left (non sub-sequence)\n",
    "        # or just the bottom (sub-sequence)\n",
    "        # find the step size\n",
    "        curStepIndex = stepsForCost[curRow, curCol]\n",
    "        curRowStep = dn[curStepIndex]\n",
    "        curColStep = dm[curStepIndex]\n",
    "        # backtrack by 1 step\n",
    "        curRow = curRow - curRowStep\n",
    "        curCol = curCol - curColStep\n",
    "        # add your new location onto the path\n",
    "        path[0, stepsInPath] = curRow\n",
    "        path[1, stepsInPath] = curCol\n",
    "        stepsInPath = stepsInPath + 1\n",
    "        # check to see if you're done\n",
    "        done = (subseq and curRow == 0) or (curRow == 0 and curCol == 0)\n",
    "\n",
    "    # reverse the path (a matrix with two rows) and return it\n",
    "    return [np.fliplr(path[:, 0:stepsInPath]), endCol, endCost]\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_time(frame, hop_length = 512, sr = 22050):\n",
    "    return frame * hop_length / sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_frame(time, hop_length = 512, sr = 22050):\n",
    "    return time * sr / hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateErrors(data, annotfile, gtfile, hop_length = 512, sr = 22050, debug = False):\n",
    "    \"\"\"Given an alignment and annotation files for the query and the reference, calculate the error between\n",
    "       each prediction from the alignment and the groud truth annotation in seconds.\"\"\"\n",
    "    wp = np.array(sorted(data, key = lambda x: x[0]))\n",
    "    query_preds = wp[:, 0]\n",
    "    ref_preds = wp[:, 1]\n",
    "    query_to_ref = np.interp(list(range(max(query_preds[-1], ref_preds[-1]) + 1)), query_preds, ref_preds)\n",
    "\n",
    "    data_gt = np.genfromtxt(gtfile, delimiter=',')\n",
    "    gt_mapping = {}\n",
    "    for time, idx in data_gt:\n",
    "        gt_mapping[idx] = time\n",
    "        \n",
    "    data_annot = np.genfromtxt(annotfile, delimiter=',')\n",
    "    errors = []\n",
    "    clicks = []\n",
    "    idxs = []\n",
    "    for time, idx in data_annot:\n",
    "        frame = int(np.round(time_to_frame(time)))\n",
    "        ref_frame = query_to_ref[frame]\n",
    "        pred_ref_time = frame_to_time(ref_frame)\n",
    "        if debug:\n",
    "            clicks.append(pred_ref_time)\n",
    "        if idx in gt_mapping:\n",
    "            error = np.abs(pred_ref_time - gt_mapping[idx])\n",
    "            idxs.append(idx)\n",
    "            errors.append(error)\n",
    "    if debug:\n",
    "        return errors, clicks\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tolerances(errors, tols):\n",
    "    \"\"\"Given a list of errors and a range of tolerances, compute the error rate \n",
    "       for each additional increment in tolerance.\"\"\"\n",
    "    errors = np.array(errors)\n",
    "    errorRates = []\n",
    "    for tol in tols:\n",
    "        toAdd = np.sum(errors > tol) * 1.0 / len(errors)\n",
    "        errorRates.append(toAdd)\n",
    "    return errorRates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align part to fullmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel = True)\n",
    "def calculate_cost_fast(query, ref):\n",
    "    \"\"\"Calculates the negative normalized min cost between the query and reference.\"\"\"\n",
    "    m, n1 = query.shape\n",
    "    m, n2 = ref.shape\n",
    "    result = np.zeros((n1, n2))\n",
    "    col_sums = np.zeros(n1)\n",
    "    for j1 in prange(n1):\n",
    "        for j2 in prange(n2):\n",
    "            for i in prange(m):\n",
    "                col_sums[j1] += query[i, j1]\n",
    "                result[j1, j2] += min(query[i, j1], ref[i, j2])\n",
    "                \n",
    "    for j1 in prange(n1):\n",
    "        for j2 in prange(n2):\n",
    "            result[j1, j2] *= -1\n",
    "            result[j1, j2] /= col_sums[j1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_part_to_fullmix(query, ref, steps = [1, 1, 1, 2, 2, 1], weights = [1, 1, 2]):\n",
    "    \"\"\"Uses subsequence DTW and the negative normalized cost metric to compute an alignment between\n",
    "       the part and full mix.\"\"\"\n",
    "    assert len(steps) % 2 == 0, \"The length of steps must be even.\"\n",
    "    dn = np.array(steps[::2], dtype=np.uint32)\n",
    "    dm = np.array(steps[1::2], dtype=np.uint32)\n",
    "    dw = weights\n",
    "    subsequence = True\n",
    "    parameter = {'dn': dn, 'dm': dm, 'dw': dw, 'SubSequence': subsequence}\n",
    "\n",
    "    # Compute cost matrix\n",
    "    cost = calculate_cost_fast(query, ref)\n",
    "    \n",
    "    # DTW\n",
    "    [D, s] = DTW_Cost_To_AccumCostAndSteps(cost, parameter)\n",
    "    [wp, endCol, endCost] = DTW_GetPath(D, s, parameter)\n",
    "\n",
    "    # Reformat the output\n",
    "    wp = wp.T[::-1]\n",
    "    return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch_part(query, ref, alignment):\n",
    "    \"\"\"Uses the alignment computed from DTW to time stretch the \n",
    "       query to have the same dimensions as the reference.\"\"\"\n",
    "    m, n = ref.shape\n",
    "    feature_stretch = np.zeros((m, n))\n",
    "    used = set(alignment[:, 1])\n",
    "    for query_idx, ref_idx in alignment:\n",
    "        feature_stretch[:, ref_idx] = query[:, query_idx]\n",
    "    for j in range(n):\n",
    "        if j not in used:\n",
    "            feature_stretch[:, j] = feature_stretch[:, j-1]\n",
    "    return feature_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel = True)\n",
    "def subtract_part(stretched_cqt, fullmix_cqt):\n",
    "    \"\"\"Subtracts the part CQT from the fullmix CQT elementwise.\"\"\"\n",
    "    m, n = stretched_cqt.shape\n",
    "    \n",
    "    for i in prange(m):\n",
    "        for j in prange(n):\n",
    "            fullmix_cqt[i, j] -= stretched_cqt[i, j]\n",
    "            fullmix_cqt[i, j] = max(fullmix_cqt[i, j], 0)\n",
    "    return fullmix_cqt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch_segments(segments, wp):\n",
    "    \"\"\"Uses the alignment created from DTW to also time stretch the nonsilence segments accordingly.\"\"\"\n",
    "    wp = np.array(sorted(wp, key = lambda x: x[0]))\n",
    "    query_preds = wp[:, 0]\n",
    "    ref_preds = wp[:, 1]\n",
    "    query_to_ref = np.interp(list(range(max(query_preds[-1], ref_preds[-1]) + 1)), query_preds, ref_preds)\n",
    "    n = len(query_to_ref) - 1\n",
    "    segments[-1][1] = min(segments[-1][1], n)\n",
    "    return [[int(query_to_ref[a]), int(query_to_ref[b])] for (a, b) in segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_segments(segments, part_cqt, fullmix_cqt):\n",
    "    \"\"\"Given a set of nonsilence segments, a part CQT, and a full mix CQT, uses an iterative algorithm\n",
    "       to find the optimal reweighting factor for each segment and scales the segment in the part CQT\n",
    "       by that factor.\"\"\"\n",
    "    alphas = np.concatenate([np.linspace(0.1, 1.0, num = 20), np.arange(1, 11, 0.3), np.arange(10, 510, 10)])\n",
    "    for segment in segments:\n",
    "        part_segment = part_cqt[:, segment[0]: segment[1] + 1]\n",
    "        fullmix_segment = fullmix_cqt[:, segment[0]: segment[1] + 1]\n",
    "        assert part_segment.shape == fullmix_segment.shape\n",
    "        best = float('-inf')\n",
    "        result = 0\n",
    "        for alpha in alphas:\n",
    "            val = np.sum(np.minimum(part_segment*alpha, fullmix_segment) - np.maximum(part_segment*alpha - fullmix_segment, 0))\n",
    "            if val > best:\n",
    "                best = val\n",
    "                result = alpha\n",
    "        part_cqt[:, segment[0]: segment[1] + 1] *= result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssa(part_cqt, fullmix_cqt, segments = []):\n",
    "    \"\"\"Performs the subtractive alignment algorithm between the part CQT and the full mix CQT\n",
    "       by first time stretching the part CQT, then performing reweighting, and then subtracting\n",
    "       the part CQT from the full mix CQT.\"\"\"\n",
    "    wp = align_part_to_fullmix(part_cqt, fullmix_cqt)\n",
    "    stretched_part = time_stretch_part(part_cqt, fullmix_cqt, wp)\n",
    "    if segments:\n",
    "        stretched_segments = stretch_segments(segments, wp)\n",
    "        weight_segments(stretched_segments, stretched_part, fullmix_cqt)\n",
    "    subtract_part(stretched_part, fullmix_cqt)\n",
    "    return fullmix_cqt, wp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get nonsilence segments in the parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silence_intervals(silence_indices):\n",
    "    \"\"\"Uses a hard silence detection approach to identify contiguous regions\n",
    "       of nonsilence.\"\"\"\n",
    "    cur_interval = []\n",
    "    start = silence_indices[0]\n",
    "    for i in range(len(silence_indices) - 1):\n",
    "        if silence_indices[i] + 1 != silence_indices[i+1]:\n",
    "            cur_interval.append((start, silence_indices[i]))\n",
    "            start = silence_indices[i+1]\n",
    "    cur_interval.append((start, silence_indices[-1]))\n",
    "    silence_intervals = []\n",
    "    for start, end in cur_interval:\n",
    "        start_time = frame_to_time(start)\n",
    "        end_time = frame_to_time(end)\n",
    "        if end_time - start_time < 2:\n",
    "            continue\n",
    "        silence_intervals.append([start, end])\n",
    "    return silence_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(total_energies):\n",
    "    \"\"\"Uses a Gaussian mixture model fitted to an array of total energies\n",
    "       to generate a threshold for nonsilence.\"\"\"\n",
    "    model = mixture.GaussianMixture(n_components=3, covariance_type=\"full\")\n",
    "    model.fit(total_energies)\n",
    "    pi, mu, sigma = model.weights_.flatten(), model.means_.flatten(), np.sqrt(model.covariances_.flatten())\n",
    "    max_idx = np.argmax(mu)\n",
    "    threshold = mu[max_idx] - 4 * sigma[max_idx]\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(audio, H=512, N=2048):\n",
    "    \"\"\"Given a piece of audio, calculates all the nonsilence segments\n",
    "       within the audio using a hard silence detection approach with GMMs.\"\"\"\n",
    "    stft = librosa.stft(audio, n_fft=N, hop_length=H)\n",
    "    energies = np.sum(np.square(abs(stft)), axis=0)\n",
    "    L = 32\n",
    "    total_energies = []\n",
    "    for i in range(len(energies)-L):\n",
    "        total_energies.append(sum(energies[i:i+L]))\n",
    "        \n",
    "    total_energies = np.log(total_energies).reshape(-1, 1)\n",
    "    threshold = get_threshold(total_energies)\n",
    "    \n",
    "    is_silence = [False] * (L//2 - 1)\n",
    "    for energy in total_energies:\n",
    "        if energy <= threshold:\n",
    "            is_silence.append(True)\n",
    "        else:\n",
    "            is_silence.append(False)\n",
    "    is_silence.extend([False] * (L//2))\n",
    "    silence_indices = np.where(np.array(is_silence) == True)[0]\n",
    "    silence_intervals = get_silence_intervals(silence_indices)\n",
    "    nonsilence_segments = []\n",
    "    cur = 0\n",
    "    for start, end in silence_intervals:\n",
    "        nonsilence_segments.append([cur, start])\n",
    "        cur = end + 1\n",
    "    nonsilence_segments.append([cur, len(is_silence)])\n",
    "    return nonsilence_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The piano has very few silence regions so we just split it into 5 second segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments_piano(piano_cqt):\n",
    "    n = piano_cqt.shape[1]\n",
    "    return [[i, min(i+215, n)] for i in range(0, n, 215)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 215 frames = 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "piano1_cqt = calculate_cqt(piano1_audio)\n",
    "violin1_cqt = calculate_cqt(violin1_audio)\n",
    "cello1_cqt = calculate_cqt(cello1_audio)\n",
    "piano2_cqt = calculate_cqt(piano2_audio)\n",
    "violin2_cqt = calculate_cqt(violin2_audio)\n",
    "cello2_cqt = calculate_cqt(cello2_audio)\n",
    "fullmix1_cqt = calculate_cqt(fullmix_audio_1)\n",
    "fullmix2_cqt = calculate_cqt(fullmix_audio_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsilence_piano1 = get_segments_piano(piano1_cqt)\n",
    "nonsilence_violin1 = get_segments(violin1_audio)\n",
    "nonsilence_cello1 = get_segments(cello1_audio)\n",
    "nonsilence_piano2 = get_segments_piano(piano2_cqt)\n",
    "nonsilence_violin2 = get_segments(violin2_audio)\n",
    "nonsilence_cello2 = get_segments(cello2_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform subtractive alignment for all 16 combinations in the train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [(0, 1), (0, 1), (0, 1), (0, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(itertools.product(*arrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "piano_segments = [nonsilence_piano1, nonsilence_piano2]\n",
    "violin_segments = [nonsilence_violin1, nonsilence_violin2]\n",
    "cello_segments = [nonsilence_cello1, nonsilence_cello2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "piano_cqts = [piano1_cqt, piano2_cqt]\n",
    "violin_cqts = [violin1_cqt, violin2_cqt]\n",
    "cello_cqts = [cello1_cqt, cello2_cqt]\n",
    "fullmix_audio = [fullmix_audio_1, fullmix_audio_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using the training set, we set increment = 1, for the test set, we set increment = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "increment = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished (0, 0, 0, 0)\n",
      "finished (0, 0, 0, 1)\n",
      "finished (0, 0, 1, 0)\n",
      "finished (0, 0, 1, 1)\n",
      "finished (0, 1, 0, 0)\n",
      "finished (0, 1, 0, 1)\n",
      "finished (0, 1, 1, 0)\n",
      "finished (0, 1, 1, 1)\n",
      "finished (1, 0, 0, 0)\n",
      "finished (1, 0, 0, 1)\n",
      "finished (1, 0, 1, 0)\n",
      "finished (1, 0, 1, 1)\n",
      "finished (1, 1, 0, 0)\n",
      "finished (1, 1, 0, 1)\n",
      "finished (1, 1, 1, 0)\n",
      "finished (1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for i, j, k, l in indices:\n",
    "    piano_cqt, cello_cqt, violin_cqt, fullmix_cqt = piano_cqts[i], cello_cqts[j], violin_cqts[k], calculate_cqt(fullmix_audio[l])\n",
    "    piano_segs, cello_segs, violin_segs = piano_segments[i], cello_segments[j], violin_segments[k]\n",
    "    \n",
    "    fullmix_cqt, piano_fullmix = ssa(piano_cqt, fullmix_cqt, piano_segs)\n",
    "    fullmix_cqt, violin_fullmix = ssa(violin_cqt, fullmix_cqt, violin_segs)\n",
    "    fullmix_cqt, cello_fullmix = ssa(cello_cqt, fullmix_cqt, cello_segs)\n",
    "    \n",
    "    piano_errs = calculateErrors(piano_fullmix, \n",
    "                                 f'data/Annotations/merged/merged/piano{i+increment}.csv', \n",
    "                                 f'data/Annotations/merged/merged/fullmix{l+increment}.csv')\n",
    "    cello_errs = calculateErrors(cello_fullmix,\n",
    "                                  f'data/Annotations/merged/merged/cello{j+increment}.csv', \n",
    "                                  f'data/Annotations/merged/merged/fullmix{l+increment}.csv')\n",
    "    violin_errs = calculateErrors(violin_fullmix,\n",
    "                                 f'data/Annotations/merged/merged/violin{k+increment}.csv', \n",
    "                                 f'data/Annotations/merged/merged/fullmix{l+increment}.csv')\n",
    "    \n",
    "    piano_tols = get_tolerances(piano_errs, np.arange(0,1,1/1000))\n",
    "    violin_tols = get_tolerances(violin_errs, np.arange(0,1,1/1000))\n",
    "    cello_tols = get_tolerances(cello_errs, np.arange(0,1,1/1000))\n",
    "    \n",
    "    with open(f\"tolerances/violin_test_alt/p{i+increment}_c{j+increment}_v{k+increment}_1a_reweight_f{l+increment}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(violin_tols, f)\n",
    "    with open(f\"tolerances/piano_test_alt/p{i+increment}_c{j+increment}_v{k+increment}_1a_reweight_f{l+increment}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(piano_tols, f)\n",
    "    with open(f\"tolerances/cello_test_alt/p{i+increment}_c{j+increment}_v{k+increment}_1a_reweight_f{l+increment}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(cello_tols, f)\n",
    "        \n",
    "    print(f\"finished {i, j, k, l}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
